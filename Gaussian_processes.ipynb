{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes with GPflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## GPflow:\n",
    "GPflow is a Gaussian process library that uses:\n",
    "- __Tensorflow__ for its core __computation__.\n",
    "- __Python__ for its __front end__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Goal features of GPflow:\n",
    "1. __Variational inference__ as primary __approximation__ method.\n",
    "2. __Automatic differentiation__ instead of gradient implementations.\n",
    "3. Leverage __GPU__ hardware for fast computation.\n",
    "4. Clean Python __OOP__.\n",
    "5. __Open source__ software principles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## GPflow meets Tensorflow:\n",
    "Computation in Tensorflow is a directed graph:\n",
    "- __nodes__ represent __operations__.\n",
    "- __edges__ represent __tensors__. <br>\n",
    "__TF_kernels__ are implementation of operations of specific device (CPU or GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP software needs the ability to solve systems of linear equations , additional contributions from GPflow developers Tensorflow:\n",
    "- C++ implementation of the __blocked Cholesky algorithm__.\n",
    "- Solving __matrix triangular systems__ on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, GPflow support __exact inference__ using __Gaussian likelihood__ (GPR-Gaussian Processes for Regression) where possible. But for __approximated inference__ it uses __Non-Gaussian likelihood__, which has two classes in GPflow:<br>\n",
    "- __Variational__: VGP-Variational Gaussian Processes.\n",
    "- __MCMC__ (Markov Chain Monte Carlo): GPMC-Gaussian Process Monte Carlo.\n",
    "\n",
    "The use of __variational sparsity__ ensures that the approximation is scalable and close the posterior (its KL divergence small).\n",
    "\n",
    "Below a table showing the inference classes in GPflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"inference.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Why we will use GPflow?\n",
    "GPflow gives around 6x performance when using GPU in comparison with ordinary Gaussian process libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gpflow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## GPflow in practice:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we have to define the compoenents of the GPflow, which defines the Gaussian process.\n",
    "\n",
    "The core components of the GPflow:\n",
    "- Models\n",
    "- Kernels\n",
    "- Likelihoods\n",
    "- Mean function\n",
    "- Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models:\n",
    "The highest level component in GPflow, usually they need at least a __kernel__ and a __likelihood__.\n",
    "\n",
    "They are listed in the table above, you can use them in GPflow by using : ___gpflow.models.'model_name'__\n",
    "\n",
    "Models in GPflow:\n",
    "1. GP regression: __.GPR__ <br>\n",
    "The basic implementation of GP regression, it has exact inference but cubic time complexity $O(n^3)$.\n",
    "We can compute the predictive distributions in closed form, as well as the marginal likelihood, which we use to estimate (optimize) the kernel parameters.\n",
    "2. Sparce GP Regression: __.SGPR__ <br>\n",
    "It uses variational formulation for sparse approximation that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood.<br>\n",
    "Time complexity from $O(n^3)$ to $O(nm^2)$ where m is the number of the inducing points.<br>\n",
    "Link to the paper:<br>\n",
    "http://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf\n",
    "3. Variational Gaussian approximation: __.VGP__<br>\n",
    "The GP posterior approximated over the function-value vector F by a multivariate Guassian, and the KL divergence is minimized between the approximation and the posterior. <br>\n",
    "The posterior approximation : $q(f)=\\mathcal{N}(f|\\mu,\\Sigma)$\n",
    "4. Sparce variational Gaussian approximation: __.SVGP__<br>\n",
    "Also uses a variational inducing points framework, equivilent or worse in time complexity in comparision with VGP.<br>\n",
    "It can used in classification problems with millions of data points.<br>\n",
    "Link to the paper: <br>\n",
    "http://proceedings.mlr.press/v38/hensman15.pdf\n",
    "5. Markov Chain Monte Carlo: __.GMPC__<br>\n",
    "Using MCMC algorithms in GP, concerns about how to efficiently sample from the posterior conditional $p(f|\\alpha,\\theta,y)$. This posterior involves a high dimensional random variable, consisting of function values that can be highly correlated with one another.\n",
    "Link to q reference:<br>\n",
    "http://www2.aueb.gr/users/mtitsias/papers/ILDMChapter09.pdf\n",
    "6. Sparce Markov Chain Monte Carlo: __.SGPMC__<br>\n",
    "Hybrid Monte Carlo smapling scheme, where used Non-Gaussian approximation over the function values and covariance parameters simultaneously, with efficient computation based on inducing pooints sparce GP.<br>\n",
    "Link to the paper:<br>\n",
    "https://core.ac.uk/download/pdf/77411843.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
